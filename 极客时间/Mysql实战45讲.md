### 01 | 基础架构：一条SQL查询语句是如何执行的？

![](https://github.com/hjy30312/picBed/blob/master/img/1.jpg?raw=true)

​																MySQL的逻辑架构图

大体来说，MySQL可以分为Server层和存储引擎层两部分。

Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM等多个存储引擎。

#### 连接器 

​	第一步，先连接到这个数据库上，这时候接待的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。`mysql - h$ip -P$port -u$user -p$password`

#### 查询缓存

​	第二步，查询缓存。MySQL拿到一个查询请求后，会先到查询缓存看看，之前是否执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果有缓存，则直接返回value，没有则执行完成后，执行结果存入查询缓存中。

##### 	但是大多数情况下不要使用查询缓存，往往弊大于利（8.0已删除查询缓存[官方说明]( https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/ ))

	1.  查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。
 	2.   对于面向用户的系统，降低性能的差异通常比提高峰值吞吐量更为重要。

#### 分析器

​	对SQL语句做解析。先会做“词法分析”，需要识别出里面的字符串分别是什么，代表什么。   其次“语法分析”，语法分析器会个根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。

#### 优化器

​	优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表有多表关联(join)的时候，决定各个表的连接顺序。

#### 执行器

	1. 先判断对表是否有查询权限。
 	2. 根据表的引擎定义，去使用这个引擎提供的接口

### 02 | 日志系统：一条SQL更新语句是如何执行的？

​	与SQL查询类似，分析器根据词法语法解析知道这是一条更新语句。优化器决定要使用ID这个索引。然后执行器负责具体执行，找到这一行，然后更新。

​	与查询流程不一样的是，更新流程还涉及到两个重要的日志模块，redo log（重做日志）和binlog（归档日志）。

#### 重要的日志模块：redo log

​	酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但是赊账的人多了，粉板总会有记不下的时候，这时候掌柜一定还有一个专门记录赊账的账本。

​	如果有人要还账或者赊账的话，掌柜一般有两种做法：

			1. 直接把账本翻出来，把这次赊的账加上去或者扣除掉；
   			2. 先在粉板上记下这次的帐，等打烊以后再把账本翻出来核算；

​	在MySQL里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程ID成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来更新效率。

​	具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。InnoDB引擎会在适当的时候，将这个操作更新到磁盘里面，而这个更新往往是系统比较空闲的时候做，这就像打烊以后掌柜做的事。

​	当粉板写满后，掌柜放下手中的活儿，把粉板一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。与此类似，InnoDB的redo log是固定大小的，可以配置一组4个文件，每个文件
的大小是 1GB，总共就4G。

​	有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。

#### 重要的日志模块：bin log

​	粉板redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。

​	这两种日志有以下三点不同。

	1.  redo log是InnoDB引擎特有的；binlog 是MySQL的Server层实现的，所有引擎都可以使用。
 	2.  redo log是物理日志，记录的是"在某个数据页上做了什么修改"；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如”给ID=2这一行的c字段加1“。
 	3.  redo log循环写的，空间固定会用完；binlog是可以追加写入的。追加写是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。



​	update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。

​		 ![](https://github.com/hjy30312/picBed/blob/master/img/update%E6%B5%81%E7%A8%8B.png?raw=true)

​										update 语句执行流程

##### 两阶段提交

​	为什么必须“两阶段提交“呢？ 这是为了让两份日志之间的逻辑一致。先写redo log后写binlog与先写binlog后写rdo log都有可能和用它的日志恢复出来的库的状态不一致。

 

### 03 | 事务隔离：为什么你改了我还看不见？

 #### 隔离性与隔离级别

​	当数据库有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了“隔离级别”的概念。

​	隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：读未提交、读提交、可重复读、串行化。

 - 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。

 - 读提交：一个事务提交之后，他做的变更才会被其他事务看到。

 - 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。在可重复隔离级别下，未提交变更对其他事务也是不可见的。

 - 串行化： 对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，访问的事务必须等前一个事务执行完成，才能继续执行。




​	在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。



#### 事务隔离的实现

​	在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

​	假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。

![](https://github.com/hjy30312/picBed/blob/master/img/事务隔离记录.png?raw=1)

​	当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

​	回滚日志什么时候删除呢？ 系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。

​	基于上面的说明，尽量不要使用长事务，长事务意味着系统里面会存在很老的事务视图，这就会导致大量占用存储空间。长事务还占用锁资源，可能拖垮整个库。

#### 事务的启动方式

MySQL的事务启动方式有以下几种：

1. 显式启动事务语句，begin或start transaction。 配套的提交语句是commit，回滚语句是rollback。

    		2.  set autocommit=0， 这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit或rollback语句，或者断开连接。

有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0  的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。



### 04 | 深入浅出索引（上）

​	索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

#### 索引的常见模型

##### 哈希表

​	哈希表示一直以键-值存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。

假设，现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引如下：

![哈希表示意图](https://github.com/hjy30312/picBed/blob/master/img/哈希表结构.png?raw=1)

 															哈希表示意图

​	图中，User2和User4根据身份证号算出来的值都是N，但没关系，后面还跟了一个链表。假设，这时候要查ID_card_n2对应的名字是什么，处理步骤就是：首先，将ID_card_n2通过哈希函数算出N；然后，按顺序遍历，找到User2。

​	但ID_card_n的值并不是递增的，这样做的好处是增加新的User时速度会很快，只需往后追加。缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。	

​	所以，**哈希表这种结构适用于只有等值查询的场景**。

#### 有序数组

​	有序数组在等值查询和范围查询场景中的性能就都非常优秀。

![](https://github.com/hjy30312/picBed/blob/master/img/有序数组表结构.png?raw=1)

 																	有序数组示意图

​	**有序数组索引值适用于静态存储引擎**，因为要保证有序，在往中间插入一个记录就必须得挪动后面所有的记录，成本太高。

​	

#### n叉树

​	二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。



​	树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左
到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。
其原因是，索引不止存在内存中，还要写到磁盘上。



​	为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。所有我们就不应该使用二叉树，而是要使用“N叉”树。“N叉”树中的“N”取决于数据块的大小。



​	以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。



​	N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。



#### InnoDB的索引模型



在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。



每一个索引在InnoDB里面对应一颗B+树。

​	

假设，有一个主键列为ID的表，表中有字段k，并且在k上有索引。 



这个表的建表语句：

```sql
CREATE TABLE T(
	id INT PRIMARY KEY,
	k INT NOT NULL,
	name VARCHAR(16),
	INDEX (k)
)ENGINE=INNODB;
```

表中 R1~R5 的 (id,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。



![](https://github.com/hjy30312/picBed/blob/master/img/InnoDB索引组织结构.png?raw=1)

 														InnoDB的索引组织结构



根据叶子节点的内容，索引类型分为主键索引和非主键索引。



主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引页被称为聚簇索引。



非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引。



##### 基于主键索引和普通索引的查询有什么区别？

- 如果语句是 `select * from T where id = 500`，即主键查询方式，则只需要搜索id这颗B+树；

- 如果语句是`selct * from T where k = 5`，即普通索引查询方式，则需要先搜索k索引树，得到id的值为500，再到id索引树搜索一次。**这个过程称为回表**。

  

也就是说，基于非主键索引的查询需要多扫描一颗索引树。因此，我们在应用中应该尽量使用主键查询。



#### 索引维护

B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新纪录。如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。



而更糟的情况是，如果R5所在的数据已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。



除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。



当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。



基于上面的索引维护过程说明，讨论一个案例：

> 你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。



自增主键是指自增列上定义的主键，插入新纪录的时候可以不指定id的值，系统会获取当前id最大值加1作为下一条记录的id值。



也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新纪录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。



而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。



除了考虑性能外，还可以从存储空间的角度看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？



由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。



**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。**所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。



### 05 | 深入浅出索引（下）



如果语句是`selct * from T where k = 5`，即普通索引查询方式，则需要先搜索k索引树，得到id的值为500，再到id索引树搜索一次。**这个过程称为回表**，由于查询结果锁需要的数据只在主键索引上有，所以不得不回表。那么有没有可能经过索引优化避免回表过程呢？

#### 覆盖索引

​	如果执行的语句是`select ID from T where k between 3 and 5`，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。在查询里，索引已经“覆盖了”我们的查询需求，称为覆盖索引。

​	**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，索引使用覆盖索引是一个常用的性能优化手段。**



问题：**在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？**

定义：

```sql
CREATE TABLE `tuser` (
	`id` int(11) NOT NULL,
	`id_card` varchar(32) DEFAULT NULL,
	`name` varchar(32) DEFAULT NULL,
	`age` int(11) DEFAULT NULL,
	`ismale` tinyint(1) DEFAULT NULL,
	PRIMARY KEY (`id`),
	KEY `id_card` (`id_card`),
	KEY `name_age` (`name`,`age`)
) ENGINE=InnoD
```

我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？



如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。



#### 最左前缀原则

​	如果每一种查询都设计一个索引，索引是不是太多了。既要保证查询速度，又要保证不可创建太多索引。如何满足呢？

​	**B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。**，为直观概念，使用（name，age）这个联合索引来分析。

![](https://github.com/hjy30312/picBed/blob/master/img/联合索引.png?raw=1)



可以看到，索引项是按照索引定义里面出现的字段顺序排序的。



查询名字”张三“或者like '张%' ， 都能够用上这个索引，找到第一个符合条件的记录，然后向后遍历，直到不满足条件为止。



所以，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。



**建立联合索引的时候，如何安排索引内的字段顺序？**

	-  第一原则，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
	-  第二原则，空间



#### 索引下推



以市民表的联合索引（name，age）为例。如果现在又一个需求：检索出表中名字第一个字是张，而且年龄是 10 岁的所有男孩”。SQL语句：

```sql
select * from tuser where name like '张%' and age = 10;
```



这个语句在搜索索引树的时候，只能用“张”，找到第一个满足条件的记录ID3。然后呢？

- 在MySQL5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再比较字段值。
- MySQL5.6引入的索引下推优化，可以在索引遍历过程中，对索引包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



### 06 | 全局锁和表锁 ： 给表加个字段怎么又这么多阻碍？

**根据加锁的范围，MySQ里面的锁大致可以分成全局锁、表级锁和行锁三类。**

#### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。**全局锁的典型使用场景是，做全库逻辑备份。** 对于InnoDB这种支持MVCC（多版本视图）的存储引擎来说，如果数据的事务级别处于可以重复读级别，备份采用mysqldump备份，通过一个命令选项[--single-transaction ]也支持逻辑一致性备份： 

`sqldump --single-transaction --master-data=2 --routines --flush-logs --databases mysql_test > alldb.sql;`



 ingle-transaction 会开启一个事务，保证读到的数据是一致的。 

#### 表级锁

MySQL里面表级有两种锁：一种是表锁，一种是元数据锁（meta data lock,MDL）。

**表锁的语法是lock tables ... read/write。**可以用unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。



举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。



**另一种表级的锁是MDL（metadata lock）**。MDL不需要显示使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。



MySQL5.5版本中引入了MDL，但对一个表最增删改查操作的时候，加MDL读表；当要对表做结构变更操作的时候，加MDL写表。

**如何安全地个小表加字段？**

MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL
NOWAIT/WAIT n 这个语法。

```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ...
```

NOWAIT 实现了非阻塞式调用，如果无法获取到 MDL 排它锁，那么会立即返回失败，而不会阻塞等待，WAIT N 则实现了最大超时 N 秒的设定，等待 N 秒后没有获取排它锁，会返回失败。

 

### 07 | 行锁功过： 怎么减少行锁对性能的影响？

MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。



#### 从两阶段锁说起

在**InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**



**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。**例子：

假设负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票、简化一下：

	1. 从顾客A账户余额中扣除电影票价；
 	2. 给影院B的账户余额增加这张电影票价；
 	3. 记录一条交易日志；

最有可能尝试事务冲突的部分就是语句2。因为要更新同一个影院账户的余额，需要修改同一行数据。

所以，根据两阶段锁协议，把语句2安排在最后。这就最大程度低减少了事务之间的锁等待，提高了并发度。但当并发足够高时，会产生死锁。

#### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程方法资源时，就会导致这几个线程都进入无线等待的状态，称为死锁。



![](https://github.com/hjy30312/picBed/blob/master/img/死锁.png?raw=1)



这时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。事务A和事务B在相互等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

	-  一种策略是，直接进入等待，直到超时。
	-  另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。

​	

正常情况下使用第二种策略，但如果大量的事务都要更新同一行的场景会导致大量的CPU资产在检测是否有死锁。**怎么解决由这种热点行更新导致的性能问题呢？**

​	**控制并发度**，基本思路就是相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。





### 09 | 普通索引和唯一索引，应该怎么选择？



![](https://github.com/hjy30312/picBed/blob/master/img/InnoDB索引组织结构.png?raw=1)

#### 查询过程

假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。

	- 对于普通索引来说，查找到满足条件的第一个记录（5，500）后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。
	- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

InnoDB的数据是按数据页为单位来读写的，每个数据页默认16kb，这个索引不同带来的性能差距微乎其微。



#### 更新过程



当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。



 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。



将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。



**什么条件下可以使用change buffer呢？**

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer 了。



因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。



**如果要在这张表中插入一个新纪录（4,400）的话，InnoDB的处理流程是怎样的。**

- 第一种情况，**这个记录要更新的目标也在内存中**。 直接判断是否存在冲突，插入，结束。

- 第二种情况，**这个记录要更新的目标页不在内存中。**这时，InnoDB的处理流程如下：

  ​	对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入，结束。

  ​    对于普通索引来说，则是将更新记录在change buffer，结束。



所以，两类索引在查询能力无区别，主要考虑的是更新性能的影响，建议选择普通索引。



#### redo log与change buffer区别

redo log主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。





### 11 | 怎么给字符串字段加索引？

假设，现在维护一个支持邮箱登录的系统，用户表示这么定义的：

```sql
CREATE TABLE user(
	id bigint unsigned primary key,
    email varchar(64),
    ...
)engine=innodb;
```



由于要使用邮箱登录，所以业务代码中一定会出现根据邮箱进行查询的语句：

```sql
select * from user where email='xxx'
```



MYSQL是支持前缀索引的，也就是说，可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。

比如，这两个在email字段上创建索引的语句：

```sql
alter table user add index index1(email);
或
alter table user add index index2(email(6));
```



两个不同的定义在存储上有明显的不同，由于email（6）这个索引结构中每个邮箱字段都只取前6个字节，所以占用的空间会更小，这就是使用前缀索引的优势。

但这同时带来的损失是，可能会增加额外的记录扫描次数。



**使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**



当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？

实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

阿里巴巴开发手册也有相关的说明：

> 【强制】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据 
>
> 实际文本区分度决定索引长度。
>
> 说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90% 
>
> 以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。 



#### 前缀索引对覆盖索引的影响

使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此。

```sql
select id,email from user where email='xxxxxxx@qq.com';
```

如果使用email整个字符串索引结构的话，就可以利用覆盖索引，无需再回表查询。如果定义了长度，则会走回表查询。

也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是在选择是否使用前缀索引时需要考虑的一个因素。



### 12 | 为什么我的MySQL会“抖”一下？

平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。



### 你的SQL语句为什么变“慢”了

InnoDB在处理更新语句的时候，只做了写日志这一个磁盘操作。 这个日志叫做redo log（重做日志），也就是掌柜用来记账的粉板，更新内存写完redo log后，就返回客户端，本次更新成功。

做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件，掌柜的记忆就是内存。 

掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内存就一致了，称为“干净页”。**

![]( https://github.com/hjy30312/picBed/blob/master/img/flush.png?raw=1)



 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。



那么，什么情况会引发数据库的flush过程呢？

-  场景一： InnoDB的redo log写满了，系统会停止所有更新操作，让redo log留出空间可以继续写。
-  场景二： 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
- 场景三：  MySQL系统空闲的时候，刷一点“脏页”。
-  场景四： MySQL正常关闭，把内存的脏页都flush到磁盘上。

**分析上面四种场景对性能的影响。**

三四对系统基本没有性能的影响。主要分析前两种：

 - 场景一： redo log写满了，要flush脏页。这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。

 - 场景二： “内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。**InnoDB用缓冲池（buffer pool）管理内存，缓存池中的内存页有三种状态：**

   ​	第一种： 还没使用；

   ​	第二种： 使用了并且是干净页；

   ​	第三种： 使用了并且是脏页；

   InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。

   

   而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。



​	所以，InnDB需要有控制脏页比例的机制，来尽量避免上面的两张情况。

#### InnoDB 刷脏页的控制策略

InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。



![]( https://github.com/hjy30312/picBed/blob/master/img/刷脏页.png?raw=1)



**平时要多关注脏页比例，不要让它经常接近 75%。**



### 13 | 为什么表数据删掉一半，表文件大小不变？